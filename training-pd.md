‡¶ñ‡ßÅ‡¶¨ ‡¶≠‡¶æ‡¶≤‡ßã ‡¶ú‡¶æ‡¶Ø‡¶º‡¶ó‡¶æ ‡¶•‡ßá‡¶ï‡ßá ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶ï‡¶∞‡¶õ üëç
‡¶Ü‡¶Æ‡¶ø ‡¶è‡¶ï‡¶¶‡¶Æ **beginner-friendly**, ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ **deep intuition + ML reality** ‡¶è‡¶ï‡¶∏‡¶æ‡¶•‡ßá explain ‡¶ï‡¶∞‡¶¨‡ßã‡•§

‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶ß‡¶æ‡¶™‡ßá ‡¶ß‡¶æ‡¶™‡ßá ‡¶Ø‡¶æ‡¶¨‡ßã‡•§

---

<details>
<summary><h1>üîµ B. Feature Normalization (Z-score) ‚Äî Deep Explanation</h1></summary>

## 1Ô∏è‚É£ Feature Normalization ‡¶Ü‡¶∏‡¶≤‡ßá ‡¶ï‡ßÄ?

‡¶§‡ßÅ‡¶Æ‡¶ø already formula ‡¶≤‡¶ø‡¶ñ‡ßá‡¶õ‡ßã:

```
X_normalized = (X - mean) / standard_deviation
```

‡¶è‡¶∞ ‡¶Æ‡¶æ‡¶®‡ßá ‡¶ï‡ßÄ?

üëâ ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶æ feature ‡¶ï‡ßá ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶è‡¶Æ‡¶®‡¶≠‡¶æ‡¶¨‡ßá ‡¶¨‡¶¶‡¶≤‡¶æ‡¶á ‡¶Ø‡ßá‡¶®:

* ‡¶§‡¶æ‡¶∞ **mean = 0**
* ‡¶§‡¶æ‡¶∞ **standard deviation = 1**

‡¶Ö‡¶∞‡ßç‡¶•‡¶æ‡ßé:

> "‡¶è‡¶á feature ‡¶ü‡¶æ average ‡¶•‡ßá‡¶ï‡ßá ‡¶ï‡¶§‡¶ü‡¶æ ‡¶â‡¶™‡¶∞‡ßá/‡¶®‡¶ø‡¶ö‡ßá?"

---

## 2Ô∏è‚É£ ‡¶ñ‡ßÅ‡¶¨ ‡¶∏‡¶π‡¶ú real-life ‡¶â‡¶¶‡¶æ‡¶π‡¶∞‡¶£ (Important)

‡¶ß‡¶∞‡ßã ‡¶§‡ßÅ‡¶Æ‡¶ø ‡¶¶‡ßÅ‡¶á‡¶ü‡¶æ ‡¶ú‡¶ø‡¶®‡¶ø‡¶∏ compare ‡¶ï‡¶∞‡¶õ‡ßã:

| Feature | Value  |
| ------- | ------ |
| Height  | 170 cm |
| Weight  | 70 kg  |

‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®:
üëâ ‡¶ï‡ßã‡¶®‡¶ü‡¶æ ‡¶¨‡ßá‡¶∂‡¶ø? 170 ‡¶®‡¶æ 70?

‚ùå ‡¶è‡¶á ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®‡¶ü‡¶æ‡¶á ‡¶≠‡ßÅ‡¶≤
‡¶ï‡¶æ‡¶∞‡¶£:

* Height ‡¶Ü‡¶∞ Weight ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ unit
* Scale ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ

Normalization ‡¶Æ‡¶æ‡¶®‡ßá:

> "‡¶è‡¶á ‡¶Æ‡¶æ‡¶®‡ßÅ‡¶∑‡¶ü‡¶æ average height ‡¶•‡ßá‡¶ï‡ßá ‡¶ï‡¶§‡¶ü‡¶æ ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ?"
> "‡¶è‡¶á ‡¶Æ‡¶æ‡¶®‡ßÅ‡¶∑‡¶ü‡¶æ average weight ‡¶•‡ßá‡¶ï‡ßá ‡¶ï‡¶§‡¶ü‡¶æ ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ?"

‡¶è‡¶á comparison ‡¶§‡¶ñ‡¶®‡¶á meaningful‡•§

---

## 3Ô∏è‚É£ ‡¶§‡ßã‡¶Æ‡¶æ‡¶∞ PD system-‡¶è ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶ï‡ßã‡¶•‡¶æ‡¶Ø‡¶º ‡¶õ‡¶ø‡¶≤?

### Raw features ‡¶è‡¶∞ scale ‡¶¶‡ßá‡¶ñ‡ßã:

| Feature | Typical Range |
| ------- | ------------- |
| MFCC    | -50 ‚Üí +50     |
| HNR     | 5 ‚Üí 30        |
| Jitter  | 0.001 ‚Üí 0.1   |
| Shimmer | 0.01 ‚Üí 0.3    |

‡¶è‡¶ñ‡¶® ‡¶≠‡¶æ‡¶¨‡ßã:

* Neural network input ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá ‡¶è‡¶ó‡ßÅ‡¶≤‡ßã ‡¶è‡¶ï‡¶∏‡¶æ‡¶•‡ßá ‡¶¢‡ßÅ‡¶ï‡¶õ‡ßá
* Network **number ‡¶¨‡ßã‡¶ù‡ßá, meaning ‡¶¨‡ßã‡¶ù‡ßá ‡¶®‡¶æ**

üëâ MFCC (¬±50) automatically ‡¶¨‡ßá‡¶∂‡¶ø "important" ‡¶π‡¶Ø‡¶º‡ßá ‡¶Ø‡¶æ‡¶¨‡ßá
üëâ Jitter (0.003) ‡¶™‡ßç‡¶∞‡¶æ‡¶Ø‡¶º invisible ‡¶π‡¶Ø‡¶º‡ßá ‡¶Ø‡¶æ‡¶¨‡ßá

‚ùå ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ clinically:

* Jitter is VERY important for PD
* MFCC ‡¶∏‡¶¨‡¶∏‡¶Æ‡¶Ø‡¶º PD-specific ‡¶®‡¶æ

---

## 4Ô∏è‚É£ Neural Network ‡¶ï‡ßÄ‡¶≠‡¶æ‡¶¨‡ßá damage ‡¶π‡¶Ø‡¶º (Beginner intuition)

### Scenario: No normalization

* MFCC = 40
* Jitter = 0.004

MLP weight update ‡¶π‡¶Ø‡¶º ‡¶è‡¶á‡¶≠‡¶æ‡¶¨‡ßá:

```
gradient ‚àù input_value √ó error
```

So,

* MFCC contribution ‚âà 40 √ó error
* Jitter contribution ‚âà 0.004 √ó error

‚ùå Network ‡¶≠‡¶æ‡¶¨‡ßá:

> "MFCC important, Jitter useless"

‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶¨‡¶æ‡¶∏‡ßç‡¶§‡¶¨‡ßá ‡¶∏‡ßá‡¶ü‡¶æ ‡¶≠‡ßÅ‡¶≤‡•§

---

## 5Ô∏è‚É£ Z-score normalization ‡¶ï‡ßÄ‡¶≠‡¶æ‡¶¨‡ßá ‡¶è‡¶ü‡¶æ ‡¶†‡¶ø‡¶ï ‡¶ï‡¶∞‡ßá?

### After normalization:

‡¶ß‡¶∞‡ßã:

* MFCC mean = 0, std = 20
* Jitter mean = 0.005, std = 0.002

Now:

```
MFCC_normalized = (40 - 0) / 20 = 2
Jitter_normalized = (0.004 - 0.005) / 0.002 = -0.5
```

üëâ ‡¶¶‡ßÅ‡¶ü‡ßã‡¶á ‡¶è‡¶ñ‡¶® **comparable scale**
üëâ Network ‡¶è‡¶ñ‡¶® ‡¶∂‡ßá‡¶ñ‡ßá:

> "‡¶è‡¶á feature ‡¶ï‡¶§‡¶ü‡¶æ abnormal?"

---

## 6Ô∏è‚É£ Gradient Descent ‡¶ï‡ßá‡¶® stable ‡¶π‡¶Ø‡¶º?

### Without normalization:

* Some weights explode (MFCC-related)
* Some weights barely update (Jitter-related)
* Loss surface = zigzag shape

Result:

* Slow convergence
* Unstable training
* Overfitting risk

### With normalization:

* All dimensions similar scale
* Loss surface smoother
* Optimizer straight path ‡¶™‡¶æ‡¶Ø‡¶º

üëâ Faster + safer learning

---

## 7Ô∏è‚É£ Contrastive Learning ‡¶è normalization ‡¶Ü‡¶∞‡¶ì ‡¶¨‡ßá‡¶∂‡¶ø ‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶ï‡ßá‡¶®?

Contrastive learning ‡¶ï‡¶∞‡ßá:

```
similarity = z_i ¬∑ z_j
```

‡¶è‡¶á dot-product sensitive to:

* magnitude
* direction

If input features not normalized:

* Embeddings biased toward high-scale features
* Distance meaningless

Z-score ensures:

* Each feature contributes **fairly**
* Embedding distance reflects **true acoustic similarity**

---

## 8Ô∏è‚É£ Feature importance ‡¶ï‡ßá‡¶® ‡¶≠‡ßÅ‡¶≤ ‡¶π‡¶Ø‡¶º normalization ‡¶õ‡¶æ‡¶°‡¶º‡¶æ?

Integrated Gradients / SHAP compute ‡¶ï‡¶∞‡ßá:

```
‚àÇprediction / ‚àÇfeature
```

If feature scale large:

* Gradient large
* Looks important

But actually:

* It's just large number, not strong signal

Normalization ensures:

> "Importance ‚â† numeric scale"

üëâ Clinical explanation trustworthy ‡¶π‡¶Ø‡¶º

---

## 9Ô∏è‚É£ Why Z-score (and not Min-Max)?

| Method        | Problem              |
| ------------- | -------------------- |
| Min-Max (0‚Äì1) | Outlier sensitive    |
| Log transform | Assumes distribution |
| Rank-based    | Loses magnitude info |

Z-score:

* Works well for near-Gaussian acoustic features
* Keeps sign (+ / -)
* Preserves deviation meaning

Medical datasets-‡¶è Z-score standard practice

---

## üîü Training vs Inference (CRITICAL DETAIL)

‚ö†Ô∏è Very important rule:

* **Mean & std compute only on training data**
* Same values used for validation & test

‚ùå Otherwise:

* Data leakage
* Inflated performance

---

## 11Ô∏è‚É£ One-line intuition (remember this)

> **Z-score normalization answers:**
> "‡¶è‡¶á feature ‡¶ü‡¶æ average ‡¶•‡ßá‡¶ï‡ßá ‡¶ï‡¶§‡¶ü‡¶æ abnormal?"

And PD detection is literally:

> **Detecting abnormal voice patterns**

---

## 12Ô∏è‚É£ If you skip normalization ‚Äî what breaks?

| Component        | Effect                  |
| ---------------- | ----------------------- |
| Encoder          | Learns wrong importance |
| Contrastive loss | Bad embeddings          |
| Classifier       | Biased decision         |
| Interpretability | Misleading              |
| LLM explanations | Wrong medical story     |

---

## 13Ô∏è‚É£ Beginner takeaway

* Neural network number ‡¶¨‡ßã‡¶ù‡ßá, unit ‡¶¨‡ßã‡¶ù‡ßá ‡¶®‡¶æ
* Normalization ‡¶®‡¶æ ‡¶ï‡¶∞‡¶≤‡ßá ML model unfair ‡¶π‡¶Ø‡¶º
* Z-score makes model **clinically fair**

---

‡¶™‡¶∞‡ßá‡¶∞ ‡¶¨‡¶æ‡¶∞ ‡¶§‡ßÅ‡¶Æ‡¶ø ‡¶ú‡¶ø‡¶ú‡ßç‡¶û‡ßá‡¶∏ ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßã:

* Why per-feature normalization, not per-sample?
* BatchNorm vs input normalization?
* What about patient-wise normalization?
* What happens if distribution shifts?
* How to handle outliers?

‡¶§‡ßÅ‡¶Æ‡¶ø ‡¶Ø‡ßá‡¶ü‡¶æ ‡¶ö‡¶æ‡¶á‡¶¨‡ßá, ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶∏‡ßá‡¶ü‡¶æ‡¶á ‡¶ß‡¶∞‡¶¨‡ßã üîç

---

‡¶ö‡¶Æ‡ßé‡¶ï‡¶æ‡¶∞ üëç
‡¶è‡¶ñ‡¶® ‡¶Ü‡¶Æ‡¶∞‡¶æ system-‡¶è‡¶∞ **‡¶∏‡¶¨‡¶ö‡ßá‡¶Ø‡¶º‡ßá ‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£ brain**‚Äì‡¶è ‡¶¢‡ßÅ‡¶ï‡¶õ‡¶ø‡•§ ‡¶Ü‡¶Æ‡¶ø ‡¶è‡¶ï‡¶¶‡¶Æ ‡¶ß‡ßÄ‡¶∞‡ßá, intuition ‚Üí math ‚Üí design decision ‡¶è‡¶á order-‡¶è explain ‡¶ï‡¶∞‡¶¨‡•§

---

</details>

<details>
<summary><h1>üß† C. Representation Encoder (MLP 24 ‚Üí 128 ‚Üí 256 ‚Üí 128)</h1></summary>

## 1Ô∏è‚É£ Representation Encoder ‡¶Ü‡¶∏‡¶≤‡ßá ‡¶ï‡ßÄ?

‡¶∏‡¶π‡¶ú ‡¶≠‡¶æ‡¶∑‡¶æ‡¶Ø‡¶º:

> **Encoder ‡¶è‡¶Æ‡¶® ‡¶è‡¶ï‡¶ü‡¶æ ‡¶Æ‡¶°‡ßá‡¶≤, ‡¶Ø‡ßá‡¶ü‡¶æ ‡¶ï‡¶æ‡¶Å‡¶ö‡¶æ feature ‡¶¶‡ßá‡¶ñ‡ßá ‡¶∞‡ßã‡¶ó‡ßÄ‡¶∞ "‡¶≠‡¶Ø‡¶º‡ßá‡¶∏‡ßá‡¶∞ ‡¶∏‡ßç‡¶¨‡¶æ‡¶ï‡ßç‡¶∑‡¶∞" ‡¶¨‡¶æ‡¶®‡¶æ‡¶Ø‡¶º‡•§**

‡¶è‡¶á ‡¶∏‡ßç‡¶¨‡¶æ‡¶ï‡ßç‡¶∑‡¶∞‡¶ü‡¶æ‡¶á ‡¶π‡¶≤‡ßã **embedding**‡•§

üëâ Classifier ‡¶∂‡ßÅ‡¶ß‡ßÅ ‡¶∂‡ßá‡¶∑ decision ‡¶®‡ßá‡¶Ø‡¶º
üëâ Encoder ‡¶∂‡ßá‡¶ñ‡ßá **‡¶ï‡ßÄ‡¶≠‡¶æ‡¶¨‡ßá ‡¶∞‡ßã‡¶ó‡ßÄ‡¶∞‡¶æ ‡¶è‡¶ï‡ßá ‡¶Ö‡¶™‡¶∞‡ßá‡¶∞ ‡¶Æ‡¶§‡ßã / ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ**

---

## 2Ô∏è‚É£ MLP ‡¶ï‡ßá‡¶®? CNN / RNN ‡¶ï‡ßá‡¶® ‡¶®‡¶æ?

‡¶ï‡¶æ‡¶∞‡¶£ ‡¶§‡ßã‡¶Æ‡¶æ‡¶∞ data:

* Tabular (24 numbers)
* No temporal sequence
* Already engineered features

So:

* CNN ‚Üí image/spatial data ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞
* RNN ‚Üí time sequence ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞
* **MLP ‚Üí best for tabular representation learning**

üëâ Simple, stable, interpretable

---

## 3Ô∏è‚É£ Layer-by-layer intuition (‡¶∏‡¶¨‡¶ö‡ßá‡¶Ø‡¶º‡ßá ‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶Ö‡¶Ç‡¶∂)

‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶è‡¶ï ‡¶è‡¶ï ‡¶ï‡¶∞‡ßá ‡¶¨‡ßÅ‡¶ù‡¶ø:

---

### üîπ Input Layer: **24 neurons**

‡¶è‡¶á 24 neuron =
24 acoustic features (Jitter, Shimmer, HNR, MFCC stats‚Ä¶)

üß† ‡¶è‡¶ñ‡¶æ‡¶®‡ßá:

* ‡¶ï‡ßã‡¶® learning ‡¶π‡¶Ø‡¶º ‡¶®‡¶æ
* ‡¶∂‡ßÅ‡¶ß‡ßÅ data ‡¶¢‡ßã‡¶ï‡ßá

---

### üîπ First Hidden Layer: **24 ‚Üí 128**

#### ‚ùì ‡¶ï‡ßá‡¶® 128? ‡¶ï‡ßá‡¶® 24 ‚Üí 24 ‡¶®‡¶æ?

‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶ï‡¶æ‡¶ú ‡¶π‡¶ö‡ßç‡¶õ‡ßá:

> **Feature interaction ‡¶∂‡ßá‡¶ñ‡¶æ**

Example:

* Jitter ‡¶è‡¶ï‡¶æ important ‡¶®‡¶æ
* Jitter + Shimmer + HNR ‡¶è‡¶ï‡¶∏‡¶æ‡¶•‡ßá PD signal

MLP ‡¶∂‡ßá‡¶ñ‡ßá:

```
new_feature_1 = f(Jitter, Shimmer)
new_feature_2 = f(HNR, MFCC1)
...
```

üëâ 24 ‚Üí 128 ‡¶Æ‡¶æ‡¶®‡ßá:

* Model-‡¶ï‡ßá "‡¶ö‡¶ø‡¶®‡ßç‡¶§‡¶æ ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ú‡¶æ‡¶Ø‡¶º‡¶ó‡¶æ" ‡¶¶‡ßá‡¶ì‡¶Ø‡¶º‡¶æ

üìå Beginner analogy:

> "‡ß®‡ß™‡¶ü‡¶æ symptom ‡¶¶‡ßá‡¶ñ‡ßá ‡¶°‡¶æ‡¶ï‡ßç‡¶§‡¶æ‡¶∞ ‡¶Æ‡¶æ‡¶•‡¶æ‡¶Ø‡¶º ‡ßß‡ß¶‡ß¶‡¶ü‡¶æ hypothesis ‡¶¨‡¶æ‡¶®‡¶æ‡¶Ø‡¶º"

---

### üîπ Second Hidden Layer: **128 ‚Üí 256 (Expansion Layer)**

‡¶§‡ßÅ‡¶Æ‡¶ø ‡¶è‡¶ï‡ßá bottleneck ‡¶¨‡¶≤‡ßá‡¶õ‡ßã, ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ technically ‡¶è‡¶ü‡¶æ **expansion layer**
(important correction!)

#### ‡¶è‡¶á layer ‡¶ï‡ßÄ ‡¶ï‡¶∞‡ßá?

‡¶è‡¶ñ‡¶æ‡¶®‡ßá model:

* Deep combinations ‡¶∂‡ßá‡¶ñ‡ßá
* Non-linear interactions ‡¶ß‡¶∞‡ßá

Example:

```
PD_signal = f(
    f(Jitter, Shimmer),
    f(HNR, MFCC_variance),
    f(RPDE, PPE)
)
```

üëâ 256 neurons ‡¶Æ‡¶æ‡¶®‡ßá:

* Rich hypothesis space
* Complex disease patterns ‡¶ß‡¶∞‡¶æ‡¶∞ ‡¶ï‡ßç‡¶∑‡¶Æ‡¶§‡¶æ

‚ùó PD heterogeneous disease ‚Äî ‡¶è‡¶á layer crucial

---

### üîπ Final Layer: **256 ‚Üí 128 (True Bottleneck)**

‡¶è‡¶á layer ‡¶Ü‡¶∏‡¶≤ **embedding** ‡¶¨‡¶æ‡¶®‡¶æ‡¶Ø‡¶º‡•§

‡¶è‡¶ü‡¶æ‡¶∞ goal:

* ‡¶∏‡¶¨ info compress ‡¶ï‡¶∞‡¶æ
* ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ PD/HC difference ‡¶∞‡¶æ‡¶ñ‡¶æ

üß† Think like:

> "‡¶∏‡¶¨ symptom summarize ‡¶ï‡¶∞‡ßá ‡¶è‡¶ï‡¶ü‡¶æ diagnosis-ready mental image"

‡¶è‡¶á embedding:

* Contrastive learning ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶¨‡ßá
* Similarity measurement ‡¶ï‡¶∞‡¶¨‡ßá
* Nearest neighbor ‡¶ñ‡ßÅ‡¶Å‡¶ú‡¶¨‡ßá

---

## 4Ô∏è‚É£ Why not 24 ‚Üí 512 ‚Üí 128?

Good question!

### Too small network:

* Underfitting
* Complex PD patterns miss

### Too large network:

* Overfitting
* Hard to train
* Embedding unstable

üëâ 24-128-256-128 = **sweet spot**

* Enough capacity
* Still regularizable

---

## 5Ô∏è‚É£ Why output = 128 dimensions?

Embedding dimension design rule:

| Dim     | Problem                   |
| ------- | ------------------------- |
| 16‚Äì32   | Too compressed, info loss |
| 64      | Okay but limited          |
| **128** | üî• Standard, stable       |
| 256+    | Hard to interpret         |

128 is widely used:

* FaceNet
* Medical embeddings
* Contrastive systems

üëâ Balance of expressiveness + stability

---

## 6Ô∏è‚É£ ReLU Activation ‚Äì ‡¶ï‡ßá‡¶®?

### ReLU formula:

```
ReLU(x) = max(0, x)
```

Meaning:

* Negative ‚Üí 0
* Positive ‚Üí unchanged

---

### ReLU ‡¶ï‡ßá‡¶® ‡¶≠‡¶æ‡¶≤‡ßã?

#### 1Ô∏è‚É£ Non-linearity ‡¶¶‡ßá‡¶Ø‡¶º

Without ReLU:

* Network = linear model
* PD patterns miss

ReLU lets model learn:

* "If jitter high AND shimmer high THEN PD"

---

#### 2Ô∏è‚É£ Sparse activation

* Many neurons = 0
* Only relevant neurons fire

üëâ Interpretability improves
üëâ Noise reduced

---

#### 3Ô∏è‚É£ Gradient problem ‡¶ï‡¶Æ

Sigmoid / tanh:

* Vanishing gradient

ReLU:

* Stable gradients
* Faster training

---

## 7Ô∏è‚É£ ReLU negative values 0 ‡¶ï‡¶∞‡ßá ‚Äî ‡¶è‡¶ü‡¶æ ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶®‡¶æ?

Good observation!

Negative values mean:

* Feature combination not useful
* Pattern not activated

In medical terms:

> "‡¶è‡¶á combination PD-related ‡¶®‡¶æ"

So ReLU acts like:

* Feature gate
* Clinical relevance filter

---

## 8Ô∏è‚É£ Encoder + Contrastive Learning relationship

Encoder ‡¶è‡¶ï‡¶æ ‡¶•‡¶æ‡¶ï‡¶≤‡ßá:

* Just transformation

Contrastive loss ‡¶Ø‡ßã‡¶ó ‡¶π‡¶≤‡ßá:

* Encoder ‡¶∂‡ßá‡¶ñ‡ßá **‡¶ï‡ßã‡¶® embedding ‡¶ï‡¶æ‡¶õ‡¶æ‡¶ï‡¶æ‡¶õ‡¶ø ‡¶π‡¶ì‡¶Ø‡¶º‡¶æ ‡¶â‡¶ö‡¶ø‡¶§**

So encoder learns:

> "PD ‡¶∞‡ßã‡¶ó‡ßÄ‡¶∞‡¶æ ‡¶è‡¶á embedding ‡¶Ö‡¶û‡ßç‡¶ö‡¶≤‡ßá ‡¶•‡¶æ‡¶ï‡ßá"

---

## 9Ô∏è‚É£ What breaks if encoder is bad?

| Problem        | Effect                   |
| -------------- | ------------------------ |
| Weak encoder   | Contrastive loss useless |
| No depth       | Linear patterns only     |
| Too deep       | Overfitting              |
| Bad activation | No meaningful embedding  |

Encoder = system foundation

---

## üîü Beginner-friendly one-liner

> **Encoder ‡¶π‡¶≤‡ßã system-‡¶è‡¶∞ "clinical brain"
> classifier ‡¶∂‡ßÅ‡¶ß‡ßÅ ‡¶Æ‡ßÅ‡¶ñ‡ßá ‡¶¨‡¶≤‡ßá PD ‡¶®‡¶æ HC**

---

## 11Ô∏è‚É£ Why MLP is perfect for YOUR case

Because you already:

* Did feature selection
* Did normalization
* Have clinically meaningful features

MLP:

* Learns interactions
* Doesn't fight data
* Complements your pipeline

---

## 12Ô∏è‚É£ Common beginner confusion (clear ‡¶ï‡¶∞‡¶ø)

‚ùå "Encoder classifier-‡¶è‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø"
‚úÖ "Encoder representation ‡¶∂‡ßá‡¶ñ‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø"

‚ùå "Classifier most important"
‚úÖ "Encoder most important"

---

## 13Ô∏è‚É£ Next natural questions (‡¶§‡ßÅ‡¶Æ‡¶ø ‡¶ú‡¶ø‡¶ú‡ßç‡¶û‡ßá‡¶∏ ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßã)

* Why BatchNorm inside encoder?
* Why Dropout?
* Why L2 normalize embedding?
* Why not skip encoder and use LR?
* What if encoder overfits?
* Why encoder shared for contrastive + classifier?

‡¶Ø‡ßá‡¶ü‡¶æ ‡¶ß‡¶∞‡¶§‡ßá ‡¶ö‡¶æ‡¶ì, ‡¶¨‡¶≤‡ßã ‚Äî ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶ì‡¶ñ‡¶æ‡¶® ‡¶•‡ßá‡¶ï‡ßá‡¶á ‡¶ó‡¶≠‡ßÄ‡¶∞‡ßá ‡¶Ø‡¶æ‡¶¨‡ßã üîç

---

‡¶ñ‡ßÅ‡¶¨ ‡¶≠‡¶æ‡¶≤‡ßã ‡¶ú‡¶æ‡¶Ø‡¶º‡¶ó‡¶æ‡¶Ø‡¶º ‡¶è‡¶∏‡ßá‡¶õ‡ßã üëç
**Latent Embedding Space** ‡¶™‡ßÅ‡¶∞‡ßã architecture-‡¶è‡¶∞ "heart".
‡¶Ü‡¶Æ‡¶ø ‡¶è‡¶ï‡¶¶‡¶Æ **beginner-friendly ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ research-grade**‡¶≠‡¶æ‡¶¨‡ßá ‡¶≠‡ßá‡¶ô‡ßá ‡¶¨‡¶≤‡¶õ‡¶ø‡•§

---

</details>

# üß† D. Latent Embedding Space (128-Dimensional)

## 1Ô∏è‚É£ Latent Embedding Space ‡¶Ü‡¶∏‡¶≤‡ßá ‡¶ï‡ßÄ?

‡¶∏‡¶π‡¶ú ‡¶≠‡¶æ‡¶∑‡¶æ‡¶Ø‡¶º:

> **Latent space ‡¶π‡¶≤‡ßã ‡¶è‡¶Æ‡¶® ‡¶è‡¶ï‡¶ü‡¶æ ‡¶ú‡¶æ‡¶Ø‡¶º‡¶ó‡¶æ, ‡¶Ø‡ßá‡¶ñ‡¶æ‡¶®‡ßá ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶æ ‡¶∞‡ßã‡¶ó‡ßÄ‡¶ï‡ßá ‡¶è‡¶ï‡¶ü‡¶æ point ‡¶¨‡¶æ‡¶®‡¶æ‡¶®‡ßã ‡¶π‡¶Ø‡¶º‡•§**

* Input: 24 acoustic features
* Output: 128 ‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶æ‡¶∞ ‡¶è‡¶ï‡¶ü‡¶æ vector

```
Patient ‚Üí [0.12, -0.45, 0.88, ..., 0.03]  (128 values)
```

‡¶è‡¶á vector:

* Raw feature ‡¶®‡¶æ
* Learned representation
* Disease-relevant information compact ‡¶ï‡¶∞‡ßá ‡¶∞‡¶æ‡¶ñ‡ßá

üìå Analogy:

> "‡ß®‡ß™‡¶ü‡¶æ symptom ‡¶¶‡ßá‡¶ñ‡ßá ‡¶°‡¶æ‡¶ï‡ßç‡¶§‡¶æ‡¶∞ ‡¶∞‡ßã‡¶ó‡ßÄ‡¶∞ ‡¶è‡¶ï‡¶ü‡¶æ mental profile ‡¶¨‡¶æ‡¶®‡¶æ‡¶Ø‡¶º"

---

## 2Ô∏è‚É£ ‡¶ï‡ßá‡¶® raw features ‡¶®‡¶æ, ‡¶ï‡ßá‡¶® latent space ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞?

Raw features:

* Independent
* Linear-ish
* Noise sensitive

Latent embedding:

* Feature interactions encode ‡¶ï‡¶∞‡ßá
* Non-linear patterns ‡¶ß‡¶∞‡ßá
* Noise suppress ‡¶ï‡¶∞‡ßá

Example:

```
Raw: jitter = high, shimmer = medium
Latent: "instability pattern" neuron fires
```

üëâ Disease signal abstract ‡¶π‡¶Ø‡¶º

---

## 3Ô∏è‚É£ 128 dimension ‡¶Æ‡¶æ‡¶®‡ßá ‡¶ï‡ßÄ ‡¶¨‡ßã‡¶ù‡¶æ‡¶Ø‡¶º?

128 = number of axes in latent space
Each dimension ‚â† one feature

Each dimension = learned concept
Example (not exact):

* dim 12 ‚Üí voice tremor pattern
* dim 47 ‚Üí breathiness instability
* dim 88 ‚Üí articulation breakdown

üß† ‡¶è‡¶ó‡ßÅ‡¶≤‡ßã human-named ‡¶®‡¶æ, ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ mathematically meaningful

---

## 4Ô∏è‚É£ ‡¶ï‡ßá‡¶® ‡¶†‡¶ø‡¶ï 128? (Design Decision)

‡¶è‡¶á‡¶ü‡¶æ random ‡¶®‡¶æ‡•§

### ‚ùå Too small (16 / 32 / 64)

* Info compress ‡¶ï‡¶∞‡¶§‡ßá ‡¶ó‡¶ø‡¶Ø‡¶º‡ßá signal ‡¶π‡¶æ‡¶∞‡¶æ‡¶Ø‡¶º
* PD subtle patterns miss

### ‚ùå Too large (256 / 512)

* Overfitting risk
* Distance meaningless (curse of dimensionality)
* Hard to interpret

### ‚úÖ 128 = sweet spot

| Reason                  | Why it matters            |
| ----------------------- | ------------------------- |
| Enough capacity         | PD heterogeneity          |
| Stable contrastive loss | Distances meaningful      |
| Good NN search          | Similar patient retrieval |
| Literature standard     | Paper-friendly            |

---

## 5Ô∏è‚É£ Contrastive learning ‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶ï‡ßÄ ‡¶ï‡¶∞‡ßá?

Contrastive loss enforce ‡¶ï‡¶∞‡ßá:

* PD ‚Üî PD ‚Üí **near**
* HC ‚Üî HC ‚Üí **near**
* PD ‚Üî HC ‚Üí **far**

Graphically:

```
   HC cluster        PD cluster
      o o o             x x x
     o o o o           x x x x
```

128-D space-‡¶è clusters clean ‡¶π‡¶Ø‡¶º

üëâ Raw feature space-‡¶è ‡¶è‡¶ü‡¶æ ‡¶∏‡¶Æ‡ßç‡¶≠‡¶¨ ‡¶®‡¶æ

---

## 6Ô∏è‚É£ Latent space medical intuition

Think like:

> "‡¶è‡¶á space-‡¶è distance ‡¶Æ‡¶æ‡¶®‡ßá clinical similarity"

* Euclidean / cosine distance = disease similarity
* Nearest neighbor = similar patient

Clinical use:

* "‡¶è‡¶á patient 7 ‡¶ú‡¶® PD ‡¶∞‡ßã‡¶ó‡ßÄ‡¶∞ ‡¶ï‡¶æ‡¶õ‡¶æ‡¶ï‡¶æ‡¶õ‡¶ø"
* "‡¶è‡¶á case borderline HC"

---

## 7Ô∏è‚É£ Why latent space improves generalization

Raw feature ML:

* Learns decision boundary
* Overfits feature values

Latent space:

* Learns **structure**
* Disease manifold capture ‡¶ï‡¶∞‡ßá

üëâ New hospital, new microphone ‚Üí still works better

---

## 8Ô∏è‚É£ Embedding ‚â† classifier output

Important distinction:

| Embedding              | Classifier     |
| ---------------------- | -------------- |
| Disease representation | Decision maker |
| Reusable               | Task-specific  |
| Contrastive trained    | CE trained     |

Same embedding ‚Üí multiple heads possible:

* PD vs HC
* Severity estimation
* Progression tracking

---

## 9Ô∏è‚É£ Why embedding is interpretable (surprisingly!)

Because you can:

* Nearest neighbor analysis
* Cluster visualization (UMAP / t-SNE)
* Feature attribution to embedding

LLM later explains:

> "Embedding shows proximity to tremor-dominant PD cases"

---

## üîü Beginner-friendly one-liner

> **Latent embedding ‡¶π‡¶≤‡ßã ‡¶∞‡ßã‡¶ó‡ßÄ‡¶∞ "compressed disease fingerprint"**

---

## 11Ô∏è‚É£ What breaks if latent space is bad?

| Problem         | Outcome                 |
| --------------- | ----------------------- |
| Poor separation | Contrastive useless     |
| Too noisy       | LLM explanation garbage |
| Too high-D      | Similarity meaningless  |
| Too low-D       | Info loss               |

So **this is NOT just a technical detail**
üëâ It defines whole system quality

---

## 12Ô∏è‚É£ Why this is paper-grade design

Because:

* Embedding space explicitly defined
* Contrastive objective justified
* Interpretability built on distances
* LLM consumes structured evidence

Reviewers love this üòâ

---

## 13Ô∏è‚É£ Next logical questions (‡¶§‡ßÅ‡¶Æ‡¶ø ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßã)

* Why L2 normalize embeddings?
* Why cosine vs Euclidean distance?
* How to visualize 128-D medically?
* What happens if PD subtypes exist?
* Should we enforce class centroids?

‡¶Ø‡ßá‡¶ü‡¶æ ‡¶ß‡¶∞‡¶§‡ßá ‡¶ö‡¶æ‡¶ì, ‡¶¨‡¶≤‡ßã ‚Äî ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶ì‡¶ñ‡¶æ‡¶®‡ßá dive ‡¶ï‡¶∞‡¶¨‡ßã üß©

---

‡¶†‡¶ø‡¶ï ‡¶Ü‡¶õ‡ßá, ‡¶ö‡¶≤ ‡¶è‡¶á **Contrastive Learning** ‡¶Ö‡¶Ç‡¶∂‡¶ü‡¶æ step-by-step, beginner-friendly, ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ research-grade‡¶≠‡¶æ‡¶¨‡ßá ‡¶¨‡¶ø‡¶∂‡ßç‡¶≤‡ßá‡¶∑‡¶£ ‡¶ï‡¶∞‡¶ø‡•§

---

# üîÑ Contrastive Learning (‡¶ï‡¶®‡ßç‡¶ü‡ßç‡¶∞‡¶æ‡¶∏‡ßç‡¶ü‡¶ø‡¶≠ ‡¶≤‡¶æ‡¶∞‡ßç‡¶®‡¶ø‡¶Ç)

## 1Ô∏è‚É£ ‡¶Æ‡ßÇ‡¶≤ ‡¶ß‡¶æ‡¶∞‡¶£‡¶æ

Contrastive learning ‡¶π‡¶≤‡ßã:

> "‡¶è‡¶ï‡¶ü‡¶ø representation ‡¶∂‡ßá‡¶ñ‡¶æ‡¶®‡ßã ‡¶Ø‡¶æ ‡¶è‡¶ï‡¶á ‡¶ß‡¶∞‡¶®‡ßá‡¶∞ samples ‡¶ï‡¶æ‡¶õ‡ßá ‡¶∞‡¶æ‡¶ñ‡ßá ‡¶è‡¶¨‡¶Ç ‡¶≠‡¶ø‡¶®‡ßç‡¶® ‡¶ß‡¶∞‡¶®‡ßá‡¶∞ samples ‡¶¶‡ßÇ‡¶∞‡ßá ‡¶∞‡¶æ‡¶ñ‡ßá‡•§"

* Input: embedding vector `z ‚àà ‚Ñù^128` (D section ‡¶•‡ßá‡¶ï‡ßá)
* Goal: PD ‚Üî PD ‚Üí ‡¶ï‡¶æ‡¶õ‡¶æ‡¶ï‡¶æ‡¶õ‡¶ø, HC ‚Üî HC ‚Üí ‡¶ï‡¶æ‡¶õ‡¶æ‡¶ï‡¶æ‡¶õ‡¶ø, PD ‚Üî HC ‚Üí ‡¶¶‡ßÇ‡¶∞‡ßá

üìå Analogy:

> "‡¶è‡¶ï‡¶á ‡¶∞‡ßã‡¶ó‡ßÄ‡¶∞ symptom fingerprint ‡¶è‡¶ï‡¶∏‡¶æ‡¶•‡ßá cluster ‡¶π‡¶¨‡ßá, ‡¶≠‡¶ø‡¶®‡ßç‡¶® ‡¶∞‡ßã‡¶ó‡ßá‡¶∞ fingerprint ‡¶¶‡ßÇ‡¶∞‡ßá ‡¶•‡¶æ‡¶ï‡¶¨‡ßá‡•§"

---

## 2Ô∏è‚É£ E [Positive Sample Pairs]

**‡¶ï‡¶ø ‡¶ï‡¶∞‡ßá?**

* ‡¶è‡¶ï class ‡¶è‡¶∞ samples ‡¶ï‡ßá positive ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá ‡¶®‡ßá‡¶Ø‡¶º
* Embedding space-‡¶è ‡¶è‡¶ó‡ßÅ‡¶≤‡ßã‡¶ï‡ßá ‡¶è‡¶ï‡¶∏‡¶æ‡¶•‡ßá ‡¶ü‡ßá‡¶®‡ßá ‡¶Ü‡¶®‡ßá

**Example:**

```
PD_patient_1 ‚Üî PD_patient_2
PD_patient_1 ‚Üî PD_patient_5
HC_patient_1 ‚Üî HC_patient_2
```

**Medical intuition:**

* ‡¶è‡¶ï‡¶á PD subtype ‡¶¨‡¶æ HC patient-‡¶è‡¶∞ voice patterns clustered ‡¶π‡¶Ø‡¶º
* Variability ‡¶ï‡¶ø‡¶õ‡ßÅ‡¶ü‡¶æ ‡¶π‡¶≤‡ßá‡¶ì embeddings ‡¶è‡¶ï‡¶á cluster-‡¶è ‡¶•‡¶æ‡¶ï‡ßá

**Extra tip:**

* ‡¶Ø‡¶¶‡¶ø ‡¶è‡¶ï patient multiple recordings ‡¶•‡¶æ‡¶ï‡ßá ‚Üí intra-patient positives ‡¶ñ‡ßÅ‡¶¨ ‡¶∂‡¶ï‡ßç‡¶§‡¶ø‡¶∂‡¶æ‡¶≤‡ßÄ

---

## 3Ô∏è‚É£ F [Negative Sample Pairs]

**‡¶ï‡¶ø ‡¶ï‡¶∞‡ßá?**

* ‡¶≠‡¶ø‡¶®‡ßç‡¶® class-‡¶è‡¶∞ samples ‡¶ï‡ßá ‡¶¶‡ßÇ‡¶∞‡ßá ‡¶∞‡¶æ‡¶ñ‡ßá
* Embedding space-‡¶è PD ‚Üî HC ‡¶¶‡ßÇ‡¶∞‡ßá

**Example:**

```
PD_patient_1 ‚Üî HC_patient_1
PD_patient_1 ‚Üî HC_patient_5
```

**Medical intuition:**

* PD patients ‡¶è‡¶ï cluster, HC ‡¶Ö‡¶®‡ßç‡¶Ø cluster ‚Üí clear separation
* Clinical boundaries represent ‡¶π‡¶Ø‡¶º embedding space-‡¶è

---

## 4Ô∏è‚É£ G [Supervised Contrastive Loss]

Mathematical formulation (simplified):

```
L_i = - (1/|P(i)|) ‚àë_{j ‚àà P(i)} log [ exp(sim(z_i, z_j)/œÑ) / ‚àë_{k ‚â† i} exp(sim(z_i, z_k)/œÑ) ]
```

Where:

| Symbol          | Meaning                                                      |
| --------------- | ------------------------------------------------------------ |
| `z_i, z_j`      | Embeddings of positive pair                                  |
| `z_k`           | Embeddings of all other samples (including negatives)        |
| `sim(z_i, z_j)` | Cosine similarity: `(z_i ¬∑ z_j) / (||z_i|| ||z_j||)`         |
| `œÑ`             | Temperature, controls softness of separation (0.07-0.1)      |

**Step-by-step intuition:**

1. Positive pair similarity ‡¶¨‡¶æ‡¶°‡¶º‡¶æ‡¶§‡ßá ‡¶ö‡¶æ‡¶Ø‡¶º
2. Negative pair similarity ‡¶ï‡¶Æ‡¶æ‡¶§‡ßá ‡¶ö‡¶æ‡¶Ø‡¶º
3. Batch-wise computation ‚Üí ‡¶∏‡¶¨ positive/negative relationships capture

---

## 5Ô∏è‚É£ ‡¶ï‡ßá‡¶® effective?

1. **Class boundaries ‡¶∂‡¶ï‡ßç‡¶§ ‡¶ï‡¶∞‡ßá:**

   * PD embeddings cluster ‚Üí HC embeddings cluster ‚Üí clear decision boundary

2. **Intra-class similarity ‡¶¨‡¶æ‡¶°‡¶º‡¶æ‡¶Ø‡¶º:**

   * Variability ‡¶•‡¶æ‡¶ï‡¶æ ‡¶∏‡¶§‡ßç‡¶§‡ßç‡¶¨‡ßá‡¶ì, same-class samples ‡¶è‡¶ï‡¶∏‡¶æ‡¶•‡ßá ‡¶•‡¶æ‡¶ï‡ßá

3. **Inter-class distance ‡¶¨‡¶æ‡¶°‡¶º‡¶æ‡¶Ø‡¶º:**

   * PD ‚Üî HC ‚Üí ‡¶¶‡ßÇ‡¶∞‡ßá ‚Üí classifier ‡¶∏‡¶π‡¶ú‡ßá decision ‡¶∂‡¶ø‡¶ñ‡ßá

4. **Medical advantage:**

   * Rare PD subtypes ‡¶¨‡¶æ early-stage PD ‚Üí embeddings still correctly cluster
   * New patient ‚Üí embedding ‚Üí nearest cluster ‚Üí interpretability

---

## 6Ô∏è‚É£ Example (Toy 2D Illustration)

```
Embedding space (2D simplified)

PD cluster:       x x x x
                  x x x
HC cluster: o o o o
            o o o

New patient z_new ‚Üí check nearest cluster ‚Üí prediction + confidence
```

* High intra-class similarity ‚Üí confidence ‚Üë
* Close to boundary ‚Üí low confidence, LLM reasoning needed

---

## 7Ô∏è‚É£ Why not just classifier?

| Classical Classifier  | Contrastive Learning                  |
| --------------------- | ------------------------------------- |
| Learns f(x) ‚Üí y       | Learns embeddings z ‚Üí relational info |
| No explicit structure | Cluster + similarity info             |
| Sensitive to noise    | Robust to inter-patient variability   |
| Hard to explain       | Embedding distance interpretable      |

---

## ‚úÖ Summary

* Positive pairs ‚Üí ‡¶è‡¶ï class-‡¶ï‡ßá ‡¶ü‡ßá‡¶®‡ßá cluster ‡¶ï‡¶∞‡ßá
* Negative pairs ‚Üí ‡¶≠‡¶ø‡¶®‡ßç‡¶® class-‡¶ï‡ßá ‡¶¶‡ßÇ‡¶∞‡ßá ‡¶∞‡¶æ‡¶ñ‡ßá
* SupCon Loss ‚Üí embedding space-‡¶è structure enforce ‡¶ï‡¶∞‡ßá
* Medical benefit ‚Üí PD subtypes, patient variability, confidence estimation

---

<details>
<summary><h1>üéØ Classification Head (128 ‚Üí 64 ‚Üí 2)</h1></summary>

### 1Ô∏è‚É£ ‡¶ï‡¶ø ‡¶ï‡¶∞‡ßá?

* **Input:** Contrastive encoder ‡¶•‡ßá‡¶ï‡ßá 128-dimensional embedding `z ‚àà ‚Ñù^128`
* **Purpose:** Embedding ‡¶•‡ßá‡¶ï‡ßá **final class probabilities** predict ‡¶ï‡¶∞‡¶æ (PD ‡¶¨‡¶æ HC)

Architecture:

```
Input: z ‚àà ‚Ñù^128
Hidden Layer: Dense(64) + ReLU + Dropout(0.2)
Output Layer: Dense(2)  # logits for PD and HC
Activation: Softmax ‚Üí probabilities
```

---

### 2Ô∏è‚É£ Why 64 neurons in hidden layer?

* **Intermediate compression:**

  * Encoder already learned rich 128-d embedding
  * 64-neuron layer ‚Üí reduces overfitting, allows learning class-specific combinations
* Acts like **"adapter"** between embedding space and output

---

### 3Ô∏è‚É£ Output Layer: 2 neurons

* Each neuron corresponds to a class:

  * `logit_PD` ‚Üí raw score for Parkinson's Disease
  * `logit_HC` ‚Üí raw score for Healthy Control

---

### 4Ô∏è‚É£ Softmax Activation

Softmax converts logits to **probabilities**:

```
P_PD = exp(logit_PD) / [exp(logit_PD) + exp(logit_HC)]
P_HC = exp(logit_HC) / [exp(logit_PD) + exp(logit_HC)]
```

* Probabilities sum to 1
* Clinically interpretable ‚Üí can be used as **confidence score**

---

### 5Ô∏è‚É£ Why not just use encoder?

* Encoder embeddings = **latent representation**
* Alone, embeddings don't give direct class probabilities
* Classifier head translates embeddings ‚Üí **actionable prediction**

**Analogy:**

* Encoder = brain that understands patient patterns
* Classification head = mouth that **says PD or HC**

---

### 6Ô∏è‚É£ Loss Function

* Use **Cross-Entropy Loss** for training:

```
L_CE = - ‚àë_{c ‚àà {PD, HC}} y_c ¬∑ log P_c
```

* `y_c` = true label (1 for correct class, 0 for others)
* Minimizing CE ‚Üí classifier learns to assign high probability to correct class

---

### 7Ô∏è‚É£ Optional: Joint Training with Contrastive Loss

* Total Loss = `Supervised Contrastive Loss + Œª * CrossEntropy Loss`
* Encoder still learns **relational structure**, classifier learns **explicit labels**

---

‚úÖ **Summary:**

* **Input:** 128-d embedding
* **Hidden Layer:** 64 neurons, ReLU, Dropout ‚Üí reduce overfitting
* **Output:** 2 logits ‚Üí Softmax ‚Üí PD vs HC probabilities
* **Loss:** Cross-Entropy (possibly combined with contrastive loss)
* **Why:** Converts embeddings into actionable, interpretable predictions

---

<details>
<summary><h2>Cross-Entropy Loss (CE Loss)</h2></summary>

## 1Ô∏è‚É£ ‡¶ï‡¶ø ‡¶ï‡¶∞‡ßá Cross-Entropy Loss?

Cross-Entropy Loss ‡¶Æ‡ßÇ‡¶≤‡¶§ **probability-based penalty**‡•§

* ‡¶Ü‡¶Æ‡¶∞‡¶æ model ‡¶ï‡ßá ‡¶¨‡¶≤‡¶õ‡¶ø:
  "Prediction probability distribution ‡¶§‡ßã‡¶Æ‡¶æ‡¶∞ output ‡¶π‡ßã‡¶ï‡•§
  True label ‡¶è‡¶∞ probability ‡¶¨‡ßá‡¶∂‡¶ø ‡¶ï‡¶∞‡ßã, ‡¶≠‡ßÅ‡¶≤‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø penalty ‡¶¶‡¶æ‡¶ì‡•§"

Formally, for binary classification (PD vs HC):

```
L_CE = - ‚àë_{c ‚àà {PD, HC}} y_c ¬∑ log P_c
```

* `y_c` = true label (PD ‚Üí [1,0], HC ‚Üí [0,1])
* `P_c` = predicted probability for class `c`

---

## 2Ô∏è‚É£ ‡¶â‡¶¶‡¶æ‡¶π‡¶∞‡¶£ ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶¨‡ßÅ‡¶ù‡¶ø

Suppose, patient is **PD** ‚Üí `y_true = [1,0]`

Model predicts: `P_pred = [0.8, 0.2]`

```
L_CE = -(1 * log 0.8 + 0 * log 0.2) = -log 0.8 ‚âà 0.223
```

* Prediction close to true label ‚Üí loss small
* Prediction wrong (e.g., `[0.3, 0.7]`) ‚Üí loss increases:

```
L_CE = -(1 * log 0.3 + 0 * log 0.7) = -log 0.3 ‚âà 1.203
```

---

## 3Ô∏è‚É£ ‡¶ï‡ßá‡¶® Cross-Entropy Loss use ‡¶ï‡¶∞‡¶ø?

1. **Probability-aware:**

   * Model ‡¶∂‡ßÅ‡¶ß‡ßÅ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ correct/incorrect predict ‡¶ï‡¶∞‡ßá ‡¶®‡¶æ, probability confidence ‡¶ì penalize ‡¶ï‡¶∞‡ßá

2. **Differentiable:**

   * Gradient descent ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶∏‡¶π‡¶ú‡ßá optimize ‡¶ï‡¶∞‡¶æ ‡¶Ø‡¶æ‡¶Ø‡¶º

3. **Standard:**

   * Multi-class (or binary) classification ‡¶è‡¶∞ industry standard

---

## 4Ô∏è‚É£ Relation with Softmax

* Softmax ‚Üí logits ‚Üí probabilities `[0,1]`
* CE Loss ‚Üí penalizes difference between **true distribution** (`y_true`) and **predicted distribution** (`y_pred`)

‚úÖ **Summary:**

* Softmax + Cross-Entropy = standard combination for classification
* Softmax converts embedding/classifier output ‚Üí probabilities
* CE Loss trains classifier ‚Üí correct probabilities

</details>

---

<details>
<summary><h2>Joint Optimization</h2></summary>

## 1Ô∏è‚É£ ‡¶ï‡¶ø ‡¶π‡¶ö‡ßç‡¶õ‡ßá ‡¶è‡¶ñ‡¶æ‡¶®‡ßá?

Joint optimization ‡¶Æ‡¶æ‡¶®‡ßá, **‡¶¶‡ßÅ‡¶ü‡¶ø loss ‡¶è‡¶ï‡¶∏‡¶æ‡¶•‡ßá minimize ‡¶ï‡¶∞‡¶æ**:

```
L_total = L_contrastive + Œª ¬∑ L_CE
```

* **L_contrastive:** Encoder ‡¶ï‡ßá ‡¶∂‡ßá‡¶ñ‡¶æ‡¶Ø‡¶º embedding space-‡¶è **similar patients ‡¶ï‡¶æ‡¶õ‡¶æ‡¶ï‡¶æ‡¶õ‡¶ø, different patients ‡¶¶‡ßÇ‡¶∞‡ßá** ‡¶∞‡¶æ‡¶ñ‡¶§‡ßá
* **L_CE:** Classifier ‡¶ï‡ßá ‡¶∂‡ßá‡¶ñ‡¶æ‡¶Ø‡¶º **‡¶∂‡ßÅ‡¶ß‡ßÅ correct class predict ‡¶ï‡¶∞‡¶§‡ßá**

---

## 2Ô∏è‚É£ ‡¶ï‡ßá‡¶® ‡¶∂‡ßÅ‡¶ß‡ßÅ ‡¶è‡¶ï‡¶ü‡¶æ‡¶á loss ‡¶®‡¶æ?

### Option A: Contrastive Loss Only

* Encoder embeddings ‡¶≠‡¶æ‡¶≤‡ßã clustered ‡¶π‡¶¨‡ßá
* ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ **classifier ‡¶†‡¶ø‡¶ï predict ‡¶®‡¶æ‡¶ì ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá**
* Probability confidence ‡¶†‡¶ø‡¶ï ‡¶π‡¶¨‡ßá ‡¶®‡¶æ

### Option B: CE Loss Only

* Classifier predict ‡¶ï‡¶∞‡¶¨‡ßá, ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ **embedding space relational info ‡¶π‡¶æ‡¶∞‡¶æ‡¶¨‡ßá**
* Similar patients similarity exploit ‡¶ï‡¶∞‡¶æ ‡¶Ø‡¶æ‡¶Ø‡¶º ‡¶®‡¶æ
* Out-of-distribution generalization ‡¶ï‡¶Æ ‡¶π‡¶¨‡ßá

### Solution: Joint

* **Encoder learns structure** (contrastive)
* **Classifier learns labels** (CE)
* ‡¶¶‡ßÅ‡¶á‡¶ü‡¶æ‡¶∞ combination ‚Üí **robust & accurate system**

---

## 3Ô∏è‚É£ Œª (Lambda) ‚Äì Balance Factor

```
L_total = L_contrastive + Œª ¬∑ L_CE
```

* Œª small ‚Üí contrastive dominate ‚Üí embeddings smooth, classifier less supervised
* Œª large ‚Üí CE dominate ‚Üí embeddings may overfit labels
* Typical value: **0.1 ‚Äì 0.3** (experimentally tune ‡¶ï‡¶∞‡¶æ ‡¶Ø‡¶æ‡¶Ø‡¶º)

---

## 4Ô∏è‚É£ Analogy

* Contrastive = "Understand relationships between patients"
* CE = "Say the correct diagnosis"
* Joint = "Understand patients **and** make correct diagnosis simultaneously"

---

## 5Ô∏è‚É£ Training Flow

```
1. Input features ‚Üí Normalization
2. Pass through Encoder ‚Üí embedding z
3. Compute:
   - L_contrastive (z distances)
   - L_CE (classifier output vs true labels)
4. L_total = L_contrastive + Œª * L_CE
5. Backpropagation ‚Üí update Encoder + Classifier weights
```

* Result: **Embedding space structured + classifier accurate**

---

‚úÖ **Summary:**

* Joint loss = best of both worlds
* Encoder embeddings become **clinically meaningful**
* Classifier predictions remain **reliable**
* Œª tuning = key hyperparameter

</details>
